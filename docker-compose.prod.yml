# Production Docker Compose Configuration for KPATA AI
# Usage: docker-compose -f docker-compose.prod.yml up -d

version: '3.8'

services:
  # Redis for BullMQ queues and rate limiting
  redis:
    image: redis:7-alpine
    container_name: kpata-redis-prod
    ports:
      - "127.0.0.1:6379:6379"  # Bind to localhost only
    volumes:
      - redis_data_prod:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-changeme}
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kpata-network-prod
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # API Service (Express)
  api:
    build:
      context: .
      dockerfile: services/api/Dockerfile
      target: production
    container_name: kpata-api-prod
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - HOST=0.0.0.0
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
    env_file:
      - services/api/.env.production
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - kpata-network-prod
    restart: always
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Worker Service (BullMQ)
  worker:
    build:
      context: .
      dockerfile: services/worker/Dockerfile
      target: production
    container_name: kpata-worker-prod
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
    env_file:
      - services/worker/.env.production
    depends_on:
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
    networks:
      - kpata-network-prod
    restart: always
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
      replicas: 1
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Web App (Next.js)
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile.prod
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-https://api.kpata-ai.online}
        - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL}
        - NEXT_PUBLIC_SUPABASE_ANON_KEY=${NEXT_PUBLIC_SUPABASE_ANON_KEY}
    image: kpata-ai-web
    container_name: kpata-ai-web
    restart: always
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-https://api.kpata-ai.online}
      - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${NEXT_PUBLIC_SUPABASE_ANON_KEY}
      - HOSTNAME=0.0.0.0
    depends_on:
      api:
        condition: service_healthy
    networks:
      - kpata-network-prod
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Admin Dashboard (Vite + React)
  admin:
    build:
      context: .
      dockerfile: apps/admin/Dockerfile.prod
      args:
        - VITE_API_URL=${VITE_API_URL:-https://api.kpata-ai.online}
        - VITE_SUPABASE_URL=${VITE_SUPABASE_URL}
        - VITE_SUPABASE_ANON_KEY=${VITE_SUPABASE_ANON_KEY}
    image: kpata-ai-admin
    container_name: kpata-ai-admin
    restart: always
    ports:
      - "3002:80"
    depends_on:
      api:
        condition: service_healthy
    networks:
      - kpata-network-prod
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Telegram Bot (optional)
  telegram-bot:
    build:
      context: .
      dockerfile: services/telegram-bot/Dockerfile
      target: production
    container_name: kpata-telegram-bot-prod
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - API_BASE_URL=http://api:3000
    env_file:
      - services/telegram-bot/.env.production
    depends_on:
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
    networks:
      - kpata-network-prod
    restart: always
    profiles:
      - with-bot
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  redis_data_prod:
    driver: local

networks:
  kpata-network-prod:
    driver: bridge
